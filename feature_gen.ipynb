{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA and Feature Generation\n",
    "\n",
    "In this notebook, we perform the exploratory data analysis (EDA) of the Quora questions pairs dataset. Then, we perform text preprocessing which includes lemmatization, tokenization, learning bigrams/trigrams and stop word removal using spaCy. Finally, we generate three types of natural language processing (NLP) features for the dataset using gensim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import needed libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#to install plotly on command line type:\n",
    "# pip install plotly\n",
    "# pip install plotly --upgrade\n",
    "import plotly as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#set up graphing utilities\n",
    "%matplotlib inline\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's have a look at the dataset first\n",
    "df = pd.read_csv(\"train.csv\").fillna(\"\")\n",
    "df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 404290 entries, 0 to 404289\n",
      "Data columns (total 6 columns):\n",
      "id              404290 non-null int64\n",
      "qid1            404290 non-null int64\n",
      "qid2            404290 non-null int64\n",
      "question1       404290 non-null object\n",
      "question2       404290 non-null object\n",
      "is_duplicate    404290 non-null int64\n",
      "dtypes: int64(4), object(2)\n",
      "memory usage: 18.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404290, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the provided training dataset has about half a million records and six columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x16fe57f0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEQCAYAAAC5oaP8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16e444e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot proportion of duplicate and non-duplicate questions\n",
    "ax = (df.groupby(\"is_duplicate\")['id'].count()/len(df)).plot.bar()\n",
    "ax.set_ylabel('Proportion')\n",
    "ax.set_title('Proportion of questions by class variable')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that about one-third of the provided question pairs are duplicate, whereas the remaining are labelled non-duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    What is the step by step guide to invest in sh...\n",
       "1    What is the story of Kohinoor (Koh-i-Noor) Dia...\n",
       "2    How can I increase the speed of my internet co...\n",
       "3    Why am I mentally very lonely? How can I solve...\n",
       "4    Which one dissolve in water quikly sugar, salt...\n",
       "Name: question1, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.question1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "Next, we use spaCy to preprocess the text that involves\n",
    "1. Conversion to unicode\n",
    "2. Lemmatization\n",
    "3. Learning bi/trigrams\n",
    "4. Removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to install spacy on command line type:\n",
    "# conda config --add channels conda-forge\n",
    "# conda install spacy\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import en_core_web_sm\n",
    "#nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['What is the step by step guide to invest in share market in india?',\n",
       "       'What is the story of Kohinoor (Koh-i-Noor) Diamond?',\n",
       "       'How can I increase the speed of my internet connection while using a VPN?',\n",
       "       ..., 'What is one coin?',\n",
       "       'What is the approx annual cost of living while studying in UIC Chicago, for an Indian student?',\n",
       "       'What is like to have sex with cousin?'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.question1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.question1.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the step by step guide to invest in share market in india?'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.question1.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'What is the step by step guide to invest in share market in india?'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.question1.values[0].decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['unicode_q1'] = df['question1'].str.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['unicode_q2'] = df['question2'].str.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>unicode_q1</th>\n",
       "      <th>unicode_q2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \\\n",
       "0  What is the step by step guide to invest in sh...             0   \n",
       "1  What would happen if the Indian government sto...             0   \n",
       "2  How can Internet speed be increased by hacking...             0   \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0   \n",
       "4            Which fish would survive in salt water?             0   \n",
       "\n",
       "                                          unicode_q1  \\\n",
       "0  What is the step by step guide to invest in sh...   \n",
       "1  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2  How can I increase the speed of my internet co...   \n",
       "3  Why am I mentally very lonely? How can I solve...   \n",
       "4  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                          unicode_q2  \n",
       "0  What is the step by step guide to invest in sh...  \n",
       "1  What would happen if the Indian government sto...  \n",
       "2  How can Internet speed be increased by hacking...  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...  \n",
       "4            Which fish would survive in salt water?  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404290, 8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_samp = df.iloc[:2500,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarma_tvxkwyx\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:1: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_samp['parsed_q1'] = df_samp['unicode_q1'].apply(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>unicode_q1</th>\n",
       "      <th>unicode_q2</th>\n",
       "      <th>parsed_q1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>(What, is, the, step, by, step, guide, to, inv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>(What, is, the, story, of, Kohinoor, (, Koh, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>(How, can, I, increase, the, speed, of, my, in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>(Why, am, I, mentally, very, lonely, ?, How, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>(Which, one, dissolve, in, water, quikly, suga...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \\\n",
       "0  What is the step by step guide to invest in sh...             0   \n",
       "1  What would happen if the Indian government sto...             0   \n",
       "2  How can Internet speed be increased by hacking...             0   \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0   \n",
       "4            Which fish would survive in salt water?             0   \n",
       "\n",
       "                                          unicode_q1  \\\n",
       "0  What is the step by step guide to invest in sh...   \n",
       "1  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2  How can I increase the speed of my internet co...   \n",
       "3  Why am I mentally very lonely? How can I solve...   \n",
       "4  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                          unicode_q2  \\\n",
       "0  What is the step by step guide to invest in sh...   \n",
       "1  What would happen if the Indian government sto...   \n",
       "2  How can Internet speed be increased by hacking...   \n",
       "3  Find the remainder when [math]23^{24}[/math] i...   \n",
       "4            Which fish would survive in salt water?   \n",
       "\n",
       "                                           parsed_q1  \n",
       "0  (What, is, the, step, by, step, guide, to, inv...  \n",
       "1  (What, is, the, story, of, Kohinoor, (, Koh, -...  \n",
       "2  (How, can, I, increase, the, speed, of, my, in...  \n",
       "3  (Why, am, I, mentally, very, lonely, ?, How, c...  \n",
       "4  (Which, one, dissolve, in, water, quikly, suga...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_samp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarma_tvxkwyx\\Anaconda2\\lib\\site-packages\\gensim\\utils.py:860: UserWarning:\n",
      "\n",
      "detected Windows; aliasing chunkize to chunkize_serial\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Phrases\n",
    "from gensim.models.word2vec import LineSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\sarma_tvxkwyx'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "qtext_filepath = r'qtext.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if 1==1:\n",
    "\n",
    "    with codecs.open(qtext_filepath, 'w', encoding='utf_8') as f:\n",
    "            for sentence in df.unicode_q1.values:\n",
    "                sentence = sentence.replace('\\n', ' ')\n",
    "                f.write(sentence + '\\n')\n",
    "            for sentence in df.unicode_q2.values:\n",
    "                sentence = sentence.replace('\\n', ' ')\n",
    "                f.write(sentence + '\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def punct_space(token):\n",
    "    \"\"\"\n",
    "    helper function to eliminate tokens\n",
    "    that are pure punctuation or whitespace\n",
    "    \"\"\"\n",
    "    \n",
    "    return token.is_punct or token.is_space\n",
    "\n",
    "def get_qline(filename):\n",
    "    \"\"\"\n",
    "    generator function to read in questions from the file\n",
    "    and un-escape the original line breaks in the text\n",
    "    \"\"\"\n",
    "    \n",
    "    with codecs.open(filename, encoding='utf_8') as f:\n",
    "        for sent in f:\n",
    "            sent = sent.replace('\\n', '')\n",
    "            yield sent\n",
    "            \n",
    "def lemmatized_sentence_corpus(filename):\n",
    "    \"\"\"\n",
    "    generator function to use spaCy to parse questions,\n",
    "    lemmatize the text, and yield sentences\n",
    "    \"\"\"\n",
    "    \n",
    "    for parsed_question in nlp.pipe(get_qline(filename),\n",
    "                                  batch_size=10000, n_threads=-1):\n",
    "        sent_out = []\n",
    "        for sent in parsed_question.sents:\n",
    "            for token in sent:\n",
    "                if not punct_space(token):\n",
    "                    sent_out.append(token.lemma_)\n",
    "        yield u' '.join(sent_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unigram_sentences_filepath = r'unigram_sentences_all.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "808580\n"
     ]
    }
   ],
   "source": [
    "# how many lines can we count directly in the file\n",
    "with codecs.open(qtext_filepath, encoding='utf_8') as f:\n",
    "    print sum((1 for _ in f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "808580\n"
     ]
    }
   ],
   "source": [
    "# how many lines can we count from the generator\n",
    "print sum((1 for _ in get_qline(qtext_filepath)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# write lemmatized unigram sentences into a file\n",
    "if 1==1:\n",
    "    with codecs.open(unigram_sentences_filepath, 'w', encoding='utf_8') as f:\n",
    "        for sentence in lemmatized_sentence_corpus(qtext_filepath):\n",
    "            f.write(sentence + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a utility function to count the number of lines in a text file\n",
    "# needed to verify that the number of lines are preserved \n",
    "# during pre-processing\n",
    "def wc_l(filename):\n",
    "    \"\"\" returns number of lines in file \"\"\"\n",
    "    with open(filename) as fin:\n",
    "        return sum((1 for _ in fin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "404290"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc_l(unigram_sentences_filepath)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we write our own LineSentence implementation because the default\n",
    "# implementation from spaCy was unnecessarily creating additional \n",
    "# sentences\n",
    "class MyLineSentence(object):\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "    def __iter__(self):\n",
    "        with codecs.open(self.filename, 'r', encoding='utf_8') as f:\n",
    "            for line in f:\n",
    "                line.replace('\\n', '')\n",
    "                yield line.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unigram_sentences = MyLineSentence(unigram_sentences_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools as it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how can -PRON- recover -PRON- gmail password\n",
      "\n",
      "how accurately can a mental illness can be diagnose\n",
      "\n",
      "be knee pain in a 20 year old girl normal\n",
      "\n",
      "what be the quality of a good leader\n",
      "\n",
      "what be the difference between bay gulf and strait\n",
      "\n",
      "will modi win in 2019\n",
      "\n",
      "how can -PRON- open dmart store in india be there any franchise for that\n",
      "\n",
      "what be the good youtube channel to learn medicine\n",
      "\n",
      "do swami vivekananda ever eat non veg or egg during -PRON- journey around the world\n",
      "\n",
      "what will happen if -PRON- cancel tqwl ticket before the charting be do\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let's have a peek at the preprocessing so far\n",
    "for unigram_sentence in it.islice(unigram_sentences, 250, 260):\n",
    "    print u' '.join(unigram_sentence)\n",
    "    print u''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigram_model_filepath = r'bigram_model_all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# learn and save the bigram model\n",
    "\n",
    "if 1==1:\n",
    "    bigram_model = Phrases(unigram_sentences)\n",
    "    bigram_model.save(bigram_model_filepath)\n",
    "\n",
    "# load the finished model from disk\n",
    "bigram_model = Phrases.load(bigram_model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigram_sentences_filepath = r'bigram_sentences_all.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarma_tvxkwyx\\Anaconda2\\lib\\site-packages\\gensim\\models\\phrases.py:274: UserWarning:\n",
      "\n",
      "For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 40.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# write sentences into a file with bigrams identified\n",
    "\n",
    "if 1==1:\n",
    "\n",
    "    with codecs.open(bigram_sentences_filepath, 'w', encoding='utf_8') as f:\n",
    "        for unigram_sentence in unigram_sentences:\n",
    "            bigram_sentence = u' '.join(bigram_model[unigram_sentence])\n",
    "            bigram_sentence = bigram_sentence.replace('\\n', '')\n",
    "            f.write(bigram_sentence + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "404290"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc_l(bigram_sentences_filepath)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigram_sentences = MyLineSentence(bigram_sentences_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how can -PRON- recover -PRON- gmail_password\n",
      "\n",
      "how accurately can a mental_illness can be diagnose\n",
      "\n",
      "be knee_pain in a 20_year old girl normal\n",
      "\n",
      "what be the quality of a good leader\n",
      "\n",
      "what be the difference_between bay gulf and strait\n",
      "\n",
      "will modi win in 2019\n",
      "\n",
      "how can -PRON- open dmart store in india be there_any franchise for that\n",
      "\n",
      "what be the good youtube_channel to learn medicine\n",
      "\n",
      "do swami_vivekananda ever eat non_veg or egg during -PRON- journey around the world\n",
      "\n",
      "what will happen if -PRON- cancel_tqwl ticket before the charting be do\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let's have another peek after the bigram processing\n",
    "for bigram_sentence in it.islice(bigram_sentences, 250, 260):\n",
    "    print u' '.join(bigram_sentence)\n",
    "    print u''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trigram_model_filepath = r'trigram_model.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 17.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# learn and save the trigram model\n",
    "\n",
    "if 1==1:\n",
    "    trigram_model = Phrases(bigram_sentences)\n",
    "    trigram_model.save(trigram_model_filepath)\n",
    "    \n",
    "# load the finished model from disk\n",
    "trigram_model = Phrases.load(trigram_model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trigram_sentences_filepath = r'trigram_sentences_all.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 39.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# write trigram sentences to file\n",
    "\n",
    "if 1==1:\n",
    "    with codecs.open(trigram_sentences_filepath, 'w', encoding='utf_8') as f:\n",
    "        for bigram_sentence in bigram_sentences:\n",
    "            trigram_sentence = u' '.join(trigram_model[bigram_sentence])\n",
    "            f.write(trigram_sentence + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "404290"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check to see if the number of lines is preserved\n",
    "wc_l(trigram_sentences_filepath)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trigram_sentences = MyLineSentence(trigram_sentences_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how can -PRON- recover -PRON- gmail_password\n",
      "\n",
      "how accurately can a mental_illness can be diagnose\n",
      "\n",
      "be knee_pain in a 20_year_old girl normal\n",
      "\n",
      "what be the quality of a good leader\n",
      "\n",
      "what be the difference_between bay gulf and strait\n",
      "\n",
      "will modi win in 2019\n",
      "\n",
      "how can -PRON- open dmart store in india be there_any franchise for that\n",
      "\n",
      "what be the good youtube_channel to learn medicine\n",
      "\n",
      "do swami_vivekananda ever eat_non_veg or egg during -PRON- journey around the world\n",
      "\n",
      "what will happen if -PRON- cancel_tqwl_ticket before the charting be do\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let's peek at the text after trigram identification\n",
    "for trigram_sentence in it.islice(trigram_sentences, 250, 260):\n",
    "    print u' '.join(trigram_sentence)\n",
    "    print u''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trigram_questions_filepath = r'trigram_transformed_questions_all.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.04 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# remove stopwords\n",
    "\n",
    "if 1==1:\n",
    "\n",
    "    with codecs.open(trigram_questions_filepath, 'w', encoding='utf_8') as f:\n",
    "        for trigram_sentence in trigram_sentences:\n",
    "            # remove any remaining stopwords\n",
    "            trigram_question = [term for term in trigram_sentence\n",
    "                              if term not in spacy.en.STOP_WORDS]\n",
    "\n",
    "            # write the transformed question as a line in the new file\n",
    "            trigram_question = u' '.join(trigram_question)\n",
    "            f.write(trigram_question + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-PRON- recover -PRON- gmail_password\n",
      "\n",
      "accurately mental_illness diagnose\n",
      "\n",
      "knee_pain 20_year_old girl normal\n",
      "\n",
      "quality good leader\n",
      "\n",
      "difference_between bay gulf strait\n",
      "\n",
      "modi win 2019\n",
      "\n",
      "-PRON- open dmart store india there_any franchise\n",
      "\n",
      "good youtube_channel learn medicine\n",
      "\n",
      "swami_vivekananda eat_non_veg egg -PRON- journey world\n",
      "\n",
      "happen -PRON- cancel_tqwl_ticket charting\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# how does the final pre-processed text look like?\n",
    "with codecs.open(trigram_questions_filepath, encoding='utf_8') as f:\n",
    "    for question in it.islice(f, 250, 260):\n",
    "        print question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Generation\n",
    "Having pre-processed the text using spaCy, we now proceed with the generation of various kinds of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load gensim for feature generation\n",
    "from gensim.corpora import Dictionary, MmCorpus\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import warnings\n",
    "import cPickle as pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dictionary of terms\n",
    "Let's first build a dictionary of terms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trigram_dictionary_filepath = r'trigram_dict_all.dict'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if 1==1:\n",
    "    trigram_questions = LineSentence(trigram_questions_filepath)\n",
    "\n",
    "    # learn the dictionary by iterating over all of the questions\n",
    "    trigram_dictionary = Dictionary(trigram_questions)\n",
    "\n",
    "    # filter tokens that are very rare or too common from\n",
    "    # the dictionary (filter_extremes) and reassign integer ids (compactify)\n",
    "    trigram_dictionary.filter_extremes(no_below=10, no_above=0.4)\n",
    "    trigram_dictionary.compactify()\n",
    "\n",
    "    trigram_dictionary.save(trigram_dictionary_filepath)\n",
    "    \n",
    "# load the finished dictionary from disk\n",
    "trigram_dictionary = Dictionary.load(trigram_dictionary_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Create a generator for bag of words (bow) model from the text of questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trigram_bow_filepath = r'trigram_bow_corpus_all.mm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trigram_bow_generator(filepath):\n",
    "    \"\"\"\n",
    "    generator function to read questions from a file\n",
    "    and yield a bag-of-words representation\n",
    "    \"\"\"\n",
    "    \n",
    "    for question in LineSentence(filepath):\n",
    "        yield trigram_dictionary.doc2bow(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create and save a Bag of Words Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 21.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if 1==1:\n",
    "    # generate bag-of-words representations for\n",
    "    # all questions and save them as a matrix\n",
    "    MmCorpus.serialize(trigram_bow_filepath,\n",
    "                       trigram_bow_generator(trigram_questions_filepath))\n",
    "    \n",
    "# load the finished bag-of-words corpus from disk\n",
    "trigram_bow_corpus = MmCorpus(trigram_bow_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# learn tfidf and load the tfidf corpus\n",
    "import gensim.models as models\n",
    "tfidf = models.TfidfModel(trigram_bow_corpus)\n",
    "corpus_tfidf = tfidf[trigram_bow_corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA Feature Generation\n",
    "From the vectorized version of the bag of words in each question, we generate the corresponding LDA features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda_model_filepath = r'lda_model_all.m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# first learn the topics from the corpus\n",
    "if 1==1:\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "\n",
    "        # workers => sets the parallelism, and should be\n",
    "        # set to your number of physical cores minus one\n",
    "        lda = LdaMulticore(trigram_bow_corpus,\n",
    "                           num_topics=50,\n",
    "                           id2word=trigram_dictionary,\n",
    "                           workers=7)\n",
    "\n",
    "    lda.save(lda_model_filepath)\n",
    "    \n",
    "# load the finished LDA model from disk\n",
    "lda = LdaMulticore.load(lda_model_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a peek at some of the learnt LDA topics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def explore_topic(topic_number, topn=25):\n",
    "    \"\"\"\n",
    "    accept a user-supplied topic number and\n",
    "    print out a formatted list of the top terms\n",
    "    \"\"\"\n",
    "        \n",
    "    print u'{:20} {}'.format(u'term', u'frequency') + u'\\n'\n",
    "\n",
    "    for term, frequency in lda.show_topic(topic_number, topn=25):\n",
    "        print u'{:20} {:.3f}'.format(term, round(frequency, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "term                 frequency\n",
      "\n",
      "book                 0.129\n",
      "good                 0.103\n",
      "read                 0.057\n",
      "phone                0.052\n",
      "game                 0.024\n",
      "engineering          0.019\n",
      "degree               0.016\n",
      "tool                 0.015\n",
      "charge               0.013\n",
      "smartphone           0.013\n",
      "complete             0.012\n",
      "ex                   0.012\n",
      "rule                 0.010\n",
      "'s                   0.008\n",
      "thrones              0.007\n",
      "series               0.007\n",
      "prepare              0.006\n",
      "statement            0.006\n",
      "improve              0.005\n",
      "financial            0.005\n",
      "touch                0.005\n",
      "write                0.005\n",
      "want                 0.005\n",
      "batman               0.005\n",
      "jee                  0.005\n"
     ]
    }
   ],
   "source": [
    "explore_topic(topic_number=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "term                 frequency\n",
      "\n",
      "answer               0.074\n",
      "safe                 0.050\n",
      "people               0.034\n",
      "black                0.030\n",
      "white                0.026\n",
      "hotel                0.025\n",
      "on_quora             0.020\n",
      "question             0.020\n",
      "brand                0.018\n",
      "true_that            0.017\n",
      "wish                 0.014\n",
      "some_mind_blow       0.013\n",
      "for_unmarried_couple 0.012\n",
      "harassment           0.012\n",
      "google               0.012\n",
      "moral_police         0.012\n",
      "police_hotel_staff   0.012\n",
      "good                 0.011\n",
      "catch                0.010\n",
      "note                 0.010\n",
      "economy              0.009\n",
      "phrase               0.009\n",
      "print                0.009\n",
      "know_about           0.009\n",
      "nation               0.008\n"
     ]
    }
   ],
   "source": [
    "explore_topic(topic_number=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "term                 frequency\n",
      "\n",
      "on_quora             0.081\n",
      "question             0.071\n",
      "ask                  0.066\n",
      "donald_trump         0.065\n",
      "hillary_clinton      0.040\n",
      "president            0.036\n",
      "good                 0.028\n",
      "example              0.024\n",
      "trump                0.023\n",
      "vote                 0.018\n",
      "people               0.014\n",
      "demonetization       0.011\n",
      "rank                 0.011\n",
      "answer               0.011\n",
      "'s                   0.008\n",
      "professional         0.008\n",
      "candidate            0.007\n",
      "package              0.006\n",
      "interview            0.006\n",
      "improve              0.006\n",
      "become_president     0.006\n",
      "pay                  0.006\n",
      "bar                  0.005\n",
      "risk                 0.005\n",
      "board                0.005\n"
     ]
    }
   ],
   "source": [
    "explore_topic(topic_number=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_trigram_question(question_number):\n",
    "    \"\"\"\n",
    "    retrieve a particular question index from the\n",
    "    trigram questions file and return it\n",
    "    \n",
    "    \"\"\"\n",
    "    with codecs.open(trigram_questions_filepath, encoding='utf_8') as f:\n",
    "        return list(it.islice(f, question_number, question_number+1))[0].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'trump_presidency_mean', u'current', u'international_master_\\u2019s', u'student', u'f1_visa']\n"
     ]
    }
   ],
   "source": [
    "print get_trigram_question(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lda_description(trigram_question, min_topic_freq=0.05):\n",
    "    \"\"\"\n",
    "    (1) create a bag-of-words\n",
    "    representation, (4) create an LDA representation, and\n",
    "    (5) print a sorted list of the top topics in the LDA representation\n",
    "    \"\"\"\n",
    "        \n",
    "    # create a bag-of-words representation\n",
    "    question_bow = trigram_dictionary.doc2bow(trigram_question)\n",
    "    \n",
    "    # create an LDA representation\n",
    "    question_lda = lda[question_bow]\n",
    "    \n",
    "    # sort with the most highly related topics first\n",
    "    question_lda = sorted(question_lda, key=lambda (topic_number, freq): -freq)\n",
    "    \n",
    "    print question_lda\n",
    "    \n",
    "    for topic_number, freq in question_lda:\n",
    "        if freq < min_topic_freq:\n",
    "            break\n",
    "            \n",
    "        # print the most highly related topic names and frequencies\n",
    "        print '{} {}'.format(topic_number,\n",
    "                                round(freq, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(46, 0.50912777676454601), (10, 0.29887222323545409)]\n",
      "46 0.509\n",
      "10 0.299\n"
     ]
    }
   ],
   "source": [
    "lda_description(get_trigram_question(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_topics_broad (fout, inp_l1, inp_l2, num_elem):\n",
    "    \"\"\"\n",
    "    saves q1 and q2 features in broad format i.e. side by side\n",
    "    \"\"\"\n",
    "    tdict_1 = dict(inp_l1)\n",
    "    tdict_2 = dict(inp_l2)\n",
    "    for i in xrange(num_elem):\n",
    "        if i in tdict_1.keys():\n",
    "            fout.write(str(tdict_1[i]) + ',')\n",
    "        else:\n",
    "            fout.write(str(0) + ',')\n",
    "    for i in xrange(num_elem):\n",
    "        if i in tdict_2.keys():\n",
    "            fout.write(str(tdict_2[i]) + ',')\n",
    "        else:\n",
    "            fout.write(str(0) + ',')\n",
    "    fout.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lda_transform(question_text):\n",
    "    \"\"\"\n",
    "    accept the original text of a question and (1) parse it with spaCy,\n",
    "    (2) apply text pre-proccessing steps, (3) create a bag-of-words\n",
    "    representation, (4) create an LDA representation, and\n",
    "    (5) print a sorted list of the top topics in the LDA representation\n",
    "    \"\"\"\n",
    "    \n",
    "    # parse the question text with spaCy\n",
    "    parsed_question = nlp(question_text)\n",
    "    \n",
    "    # lemmatize the text and remove punctuation and whitespace\n",
    "    unigram_question = [token.lemma_ for token in parsed_question\n",
    "                      if not punct_space(token)]\n",
    "    \n",
    "    # apply the first-order and secord-order phrase models\n",
    "    bigram_question = bigram_model[unigram_question]\n",
    "    trigram_question = trigram_model[bigram_question]\n",
    "    \n",
    "    # remove any remaining stopwords\n",
    "    trigram_question = [term for term in trigram_question\n",
    "                      if not term in spacy.en.STOP_WORDS]\n",
    "    \n",
    "    # create a bag-of-words representation\n",
    "    question_bow = trigram_dictionary.doc2bow(trigram_question)\n",
    "    \n",
    "    # create an LDA representation\n",
    "    question_lda = lda[question_bow]\n",
    "    \n",
    "    # sort with the most highly related topics first\n",
    "    question_lda = sorted(question_lda, key=lambda (topic_number, freq): -freq)\n",
    "    \n",
    "    return question_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>unicode_q1</th>\n",
       "      <th>unicode_q2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \\\n",
       "0  What is the step by step guide to invest in sh...             0   \n",
       "1  What would happen if the Indian government sto...             0   \n",
       "2  How can Internet speed be increased by hacking...             0   \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0   \n",
       "4            Which fish would survive in salt water?             0   \n",
       "\n",
       "                                          unicode_q1  \\\n",
       "0  What is the step by step guide to invest in sh...   \n",
       "1  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2  How can I increase the speed of my internet co...   \n",
       "3  Why am I mentally very lonely? How can I solve...   \n",
       "4  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                          unicode_q2  \n",
       "0  What is the step by step guide to invest in sh...  \n",
       "1  What would happen if the Indian government sto...  \n",
       "2  How can Internet speed be increased by hacking...  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...  \n",
       "4            Which fish would survive in salt water?  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404290, 8)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the LDA data into files for model building purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda_data50b_filepath = r'lda_data50b_all.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if 1==1:\n",
    "    n_pairs = len(df)\n",
    "    batch_size = 1000\n",
    "    with codecs.open(lda_data50b_filepath, 'w', encoding='utf_8') as f_out:\n",
    "        for i in tqdm(xrange(1, n_pairs/batch_size)):\n",
    "            df_batch = df.iloc[(i-1)*batch_size:i*batch_size,:].copy()\n",
    "            df_batch['q1_lda'] = df_batch['unicode_q1'].apply(lda_transform)\n",
    "            df_batch['q2_lda'] = df_batch['unicode_q2'].apply(lda_transform)\n",
    "            for q1, q2 in zip(df_batch.q1_lda.values, df_batch.q2_lda.values):\n",
    "                save_topics_broad(f_out, q1, q2, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if 1==1:\n",
    "    with codecs.open(lda_data50b_filepath, 'a', encoding='utf_8') as f_out:\n",
    "        df_batch = df.iloc[i*batch_size:,:].copy()\n",
    "        df_batch['q1_lda'] = df_batch['unicode_q1'].apply(lda_transform)\n",
    "        df_batch['q2_lda'] = df_batch['unicode_q2'].apply(lda_transform)\n",
    "        for q1, q2 in zip(df_batch.q1_lda.values, df_batch.q2_lda.values):\n",
    "            save_topics_broad(f_out, q1, q2, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda_model300_filepath = r'lda_model_300_all.m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if 1==1:\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "\n",
    "        # workers => sets the parallelism, and should be\n",
    "        # set to your number of physical cores minus one\n",
    "        lda = LdaMulticore(trigram_bow_corpus,\n",
    "                           num_topics=300,\n",
    "                           id2word=trigram_dictionary,\n",
    "                           workers=7)\n",
    "\n",
    "    lda.save(lda_model300_filepath)\n",
    "    \n",
    "# load the finished LDA model from disk\n",
    "lda = LdaMulticore.load(lda_model300_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda_data300b_filepath = r'lda_data300b_all.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if 1==1:\n",
    "    n_pairs = len(df)\n",
    "    batch_size = 1000\n",
    "    with codecs.open(lda_data300b_filepath, 'w', encoding='utf_8') as f_out:\n",
    "        for i in tqdm(xrange(1, n_pairs/batch_size)):\n",
    "            df_batch = df.iloc[(i-1)*batch_size:i*batch_size,:].copy()\n",
    "            df_batch['q1_lda'] = df_batch['unicode_q1'].apply(lda_transform)\n",
    "            df_batch['q2_lda'] = df_batch['unicode_q2'].apply(lda_transform)\n",
    "            for q1, q2 in zip(df_batch.q1_lda.values, df_batch.q2_lda.values):\n",
    "                save_topics_broad(f_out, q1, q2, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if 1==1:\n",
    "    with codecs.open(lda_data300b_filepath, 'a', encoding='utf_8') as f_out:\n",
    "        df_batch = df.iloc[i*batch_size:,:].copy()\n",
    "        df_batch['q1_lda'] = df_batch['unicode_q1'].apply(lda_transform)\n",
    "        df_batch['q2_lda'] = df_batch['unicode_q2'].apply(lda_transform)\n",
    "        for q1, q2 in zip(df_batch.q1_lda.values, df_batch.q2_lda.values):\n",
    "            save_topics_broad(f_out, q1, q2, 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSI Feature Generation\n",
    "From the vectorized version of the bag of words in each question, we generate the corresponding LSI features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsi_model_filepath = r'lsi_model_all.m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.models.lsimodel import LsiModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 20min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if 1==1:\n",
    "    #import logging\n",
    "    #logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "    #logger = logging.getLogger()\n",
    "    #logger.propagate = False\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "\n",
    "        trigram_dictionary = Dictionary.load(trigram_dictionary_filepath)\n",
    "        lsi = LsiModel(corpus_tfidf,\n",
    "                           num_topics=300,\n",
    "                           id2word=trigram_dictionary,\n",
    "                           chunksize=2000)\n",
    "\n",
    "    lsi.save(lsi_model_filepath)\n",
    "    \n",
    "# load the finished Lsimodel from disk\n",
    "lsi = LsiModel.load(lsi_model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lsi_transform(question_text):\n",
    "    \"\"\"\n",
    "    accept the original text of a question and (1) parse it with spaCy,\n",
    "    (2) apply text pre-proccessing steps, (3) create a bag-of-words\n",
    "    representation, (4) create an LSI representation, and\n",
    "    (5) print a sorted list of the top topics in the LSI representation\n",
    "    \"\"\"\n",
    "    \n",
    "    # parse the question text with spaCy\n",
    "    parsed_question = nlp(question_text)\n",
    "    \n",
    "    # lemmatize the text and remove punctuation and whitespace\n",
    "    unigram_question = [token.lemma_ for token in parsed_question\n",
    "                      if not punct_space(token)]\n",
    "    \n",
    "    # apply the first-order and secord-order phrase models\n",
    "    bigram_question = bigram_model[unigram_question]\n",
    "    trigram_question = trigram_model[bigram_question]\n",
    "    \n",
    "    # remove any remaining stopwords\n",
    "    trigram_question = [term for term in trigram_question\n",
    "                      if not term in spacy.en.STOP_WORDS]\n",
    "    \n",
    "    # create a bag-of-words representation\n",
    "    question_bow = trigram_dictionary.doc2bow(trigram_question)\n",
    "    \n",
    "    question_tfidf = tfidf[question_bow]\n",
    "    \n",
    "    # create an Lsi representation\n",
    "    question_lsi = lsi[question_bow]\n",
    "    \n",
    "    # sort with the most highly related topics first\n",
    "    question_lsi = sorted(question_lsi, key=lambda (topic_number, freq): -freq)\n",
    "    \n",
    "    return question_lsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsi_data300b_filepath = r'lsi_data300b_all.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if 1==1:\n",
    "    n_pairs = len(df)\n",
    "    batch_size = 1000\n",
    "    with codecs.open(lsi_data300b_filepath, 'w', encoding='utf_8') as f_out:\n",
    "        for i in tqdm(xrange(1, n_pairs/batch_size)):\n",
    "            df_batch = df.iloc[(i-1)*batch_size:i*batch_size,:].copy()\n",
    "            df_batch['q1_lsi'] = df_batch['unicode_q1'].apply(lsi_transform)\n",
    "            df_batch['q2_lsi'] = df_batch['unicode_q2'].apply(lsi_transform)\n",
    "            for q1, q2 in zip(df_batch.q1_lsi.values, df_batch.q2_lsi.values):\n",
    "                save_topics_broad(f_out, q1, q2, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if 1==1:\n",
    "    with codecs.open(lsi_data300b_filepath, 'a', encoding='utf_8') as f_out:\n",
    "        df_batch = df.iloc[i*batch_size:,:].copy()\n",
    "        df_batch['q1_lsi'] = df_batch['unicode_q1'].apply(lsi_transform)\n",
    "        df_batch['q2_lsi'] = df_batch['unicode_q2'].apply(lsi_transform)\n",
    "        for q1, q2 in zip(df_batch.q1_lsi.values, df_batch.q2_lsi.values):\n",
    "            save_topics_broad(f_out, q1, q2, 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Doc2Vec Feature Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d2v_model_filepath = r'd2v_model.m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import TaggedLineDocument\n",
    "from gensim.models import Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trigram_questions_filepath = r'trigram_transformed_questions_all.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 42min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if 1==1:\n",
    "    train_sentences = TaggedLineDocument(trigram_questions_filepath)\n",
    "    d2v_model = Doc2Vec(dm=1, dm_mean=1,\n",
    "                        size=400, window=10, negative=5, hs=0,\n",
    "                        min_count=2, alpha=0.025, \n",
    "                        min_alpha=0.001, iter=50,\n",
    "                        workers=7)\n",
    "    d2v_model.build_vocab(train_sentences)\n",
    "    d2v_model.train(train_sentences, total_examples=d2v_model.corpus_count,\n",
    "                epochs=d2v_model.iter)\n",
    "    d2v_model.delete_temporary_training_data(keep_doctags_vectors=True, \n",
    "                                         keep_inference=True)\n",
    "    \n",
    "    d2v_model.save(d2v_model_filepath)\n",
    "d2v_model = Doc2Vec.load(d2v_model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -9.82174203e-02,   3.13738696e-02,   4.10821065e-02,\n",
       "         4.61697765e-02,   5.89968152e-02,   6.00745250e-03,\n",
       "         8.25706273e-02,  -5.78361265e-02,   2.31606551e-02,\n",
       "         4.56802100e-02,  -2.73349918e-02,   1.59479249e-02,\n",
       "         4.87788208e-02,  -2.78492216e-02,   1.07609846e-01,\n",
       "         4.77705635e-02,   6.16812427e-03,  -9.93105695e-02,\n",
       "         6.48889244e-02,  -3.75628434e-02,  -1.68333277e-02,\n",
       "         7.94352517e-02,   2.01203600e-02,   3.73165905e-02,\n",
       "         7.33051598e-02,  -1.08407915e-01,  -5.04615018e-05,\n",
       "        -6.01253547e-02,   1.60108805e-02,  -1.44081460e-02,\n",
       "         1.23247579e-01,  -2.98242979e-02,   1.50347175e-02,\n",
       "        -2.70194970e-02,  -2.50659883e-02,  -5.62339686e-02,\n",
       "        -2.43297522e-03,  -5.55542996e-04,   8.06506202e-02,\n",
       "         1.04231149e-01,  -6.48791119e-02,   1.05931321e-02,\n",
       "        -2.17529573e-02,  -4.20880653e-02,   3.03923562e-02,\n",
       "        -5.59917241e-02,  -3.77791151e-02,  -1.00029409e-02,\n",
       "        -4.96916696e-02,  -6.60464391e-02,   1.53842419e-02,\n",
       "         1.29191071e-01,   2.02152506e-02,   7.58825941e-03,\n",
       "         3.97253409e-02,  -3.61862890e-02,   9.35336873e-02,\n",
       "        -5.73319085e-02,  -6.40500858e-02,  -1.03629217e-01,\n",
       "         5.64004220e-02,   3.26946564e-02,   2.91134398e-02,\n",
       "         6.56727925e-02,  -1.36861637e-01,   1.57726686e-02,\n",
       "        -1.19922578e-01,   2.84746867e-02,  -3.41966785e-02,\n",
       "        -1.10118296e-02,   6.64281473e-02,  -6.21099286e-02,\n",
       "         8.72575771e-03,  -1.10660329e-01,  -1.31165516e-02,\n",
       "         1.27534211e-01,   1.55635271e-02,   1.14519326e-02,\n",
       "        -5.06070629e-02,   4.04349044e-02,   5.77220060e-02,\n",
       "        -6.81800842e-02,  -2.07007229e-02,   7.70473033e-02,\n",
       "        -2.38035806e-03,   6.51986375e-02,   2.35345494e-02,\n",
       "        -8.86658789e-04,   3.56159993e-02,   1.01017676e-01,\n",
       "        -2.48699803e-02,  -8.94211978e-03,   4.61590886e-02,\n",
       "         4.36278246e-02,  -4.85430192e-03,  -6.87237605e-02,\n",
       "        -7.73421079e-02,  -4.43050526e-02,  -1.73062626e-02,\n",
       "        -4.09528725e-02,  -2.90957838e-02,   2.11352343e-03,\n",
       "         4.36117053e-02,   9.47802502e-04,   9.35794413e-03,\n",
       "        -6.87907115e-02,   4.95814718e-02,  -2.57711057e-02,\n",
       "         3.15869343e-03,  -8.15816671e-02,   4.42663692e-02,\n",
       "         5.56903295e-02,  -1.19524553e-01,   8.02932829e-02,\n",
       "         1.01479441e-01,  -4.59193103e-02,   3.69500229e-03,\n",
       "         1.76628921e-02,   5.54645713e-03,   6.27213418e-02,\n",
       "        -9.42215994e-02,   4.93370108e-02,   7.34254858e-03,\n",
       "        -6.66426122e-02,  -2.81359628e-02,  -8.37625563e-03,\n",
       "         8.73138458e-02,  -2.96441764e-02,   5.86856417e-02,\n",
       "        -5.57235219e-02,   3.69031839e-02,  -1.46893933e-01,\n",
       "         1.00641564e-01,   2.08128896e-02,  -3.47638056e-02,\n",
       "        -3.28558646e-02,   8.41874909e-03,   8.24359134e-02,\n",
       "         8.21325090e-03,   3.27512063e-02,   1.63435694e-02,\n",
       "         3.27622965e-02,  -9.53276157e-02,   9.55719054e-02,\n",
       "         2.02334318e-02,   9.04773828e-03,   1.87618226e-01,\n",
       "        -4.19393778e-02,   6.64994214e-03,  -5.11051435e-03,\n",
       "         3.35623398e-02,   1.22198230e-02,   5.08761071e-02,\n",
       "        -8.66487101e-02,   3.79088633e-02,   3.69416885e-02,\n",
       "        -2.72592939e-02,   3.33283208e-02,   1.08236298e-02,\n",
       "        -3.58448140e-02,   1.05383829e-03,  -1.37876675e-01,\n",
       "         6.73543736e-02,  -4.33136001e-02,   2.79542599e-02,\n",
       "         2.81862225e-02,  -8.43685493e-02,   6.43404527e-03,\n",
       "        -7.53973785e-04,   5.34118935e-02,   5.86256012e-02,\n",
       "        -1.57593518e-01,   1.89766139e-02,   3.72798257e-02,\n",
       "         1.84743423e-02,   9.30320844e-02,  -7.98687898e-03,\n",
       "        -2.30777799e-03,  -1.46944612e-01,   9.59912911e-02,\n",
       "        -4.17996831e-02,   9.93833765e-02,  -3.26115489e-02,\n",
       "        -6.52218238e-02,   3.70941423e-02,   2.20556129e-02,\n",
       "         7.47158285e-03,   1.41080556e-04,   9.92650315e-02,\n",
       "         9.14081857e-02,   2.34592259e-02,   1.47401430e-02,\n",
       "        -4.50426713e-02,  -2.64379289e-02,   7.15596303e-02,\n",
       "         3.71451303e-02,  -4.19832207e-02,   5.36455177e-02,\n",
       "         2.66460124e-02,  -9.41184387e-02,   4.46314402e-02,\n",
       "        -7.19358679e-03,  -2.61966232e-02,   2.66629551e-02,\n",
       "        -5.74771240e-02,  -8.97313375e-03,  -2.30053253e-02,\n",
       "         2.27899179e-02,   1.82606120e-04,   2.18725037e-02,\n",
       "        -3.09517533e-02,  -1.31384302e-02,  -2.74440851e-02,\n",
       "         2.08670329e-02,  -6.65643215e-02,   7.58349570e-03,\n",
       "         8.56387690e-02,  -2.33158357e-02,   1.57246031e-02,\n",
       "        -8.30651075e-02,   8.12037587e-02,  -5.41588925e-02,\n",
       "        -9.32720839e-04,  -1.08783811e-01,   8.51502195e-02,\n",
       "         1.01377880e-02,   5.57110310e-02,   7.18192607e-02,\n",
       "        -1.40419081e-02,  -5.49867153e-02,  -6.20694906e-02,\n",
       "         8.10320452e-02,   5.78139871e-02,   3.40308733e-02,\n",
       "        -3.61051634e-02,   3.59536707e-02,   7.94829102e-04,\n",
       "        -6.74146637e-02,   6.94574639e-02,  -1.75726265e-02,\n",
       "         1.75793041e-02,   9.84320417e-02,   3.74622010e-02,\n",
       "         4.25127633e-02,  -1.16511192e-02,   5.11101261e-02,\n",
       "        -8.51564016e-03,   9.55304578e-02,  -2.24137609e-03,\n",
       "         7.39455689e-03,  -1.14561571e-02,  -6.58517331e-02,\n",
       "        -2.53720153e-02,   2.48380750e-02,   3.12111024e-02,\n",
       "        -1.91059969e-02,  -8.89840629e-03,  -6.30660588e-03,\n",
       "         7.26088434e-02,   3.36759500e-02,   8.86052921e-02,\n",
       "        -1.17035545e-02,  -9.48406905e-02,   4.99922968e-02,\n",
       "         4.49923649e-02,   3.87215912e-02,   6.98822513e-02,\n",
       "        -2.54135090e-03,   1.03398897e-01,  -4.45415415e-02,\n",
       "         2.50013564e-02,   4.02994491e-02,  -1.30920038e-01,\n",
       "        -4.79575358e-02,  -8.22631866e-02,   1.26389384e-01,\n",
       "         6.07114322e-02,   3.58005203e-02,  -6.58585429e-02,\n",
       "         5.52612096e-02,  -4.70334711e-03,  -3.06292716e-02,\n",
       "        -2.02938523e-02,   1.07915930e-01,  -4.26392034e-02,\n",
       "         8.35033692e-03,  -3.22814249e-02,  -2.49004737e-02,\n",
       "         9.16804094e-03,   4.19223197e-02,  -7.37982914e-02,\n",
       "         1.80154562e-03,  -5.26931770e-02,   6.40485883e-02,\n",
       "        -1.88681353e-02,   2.77751628e-02,   6.02694275e-03,\n",
       "         1.04657091e-01,   8.24002624e-02,   1.69000048e-02,\n",
       "         1.31768897e-01,  -1.88680552e-02,  -6.77728951e-02,\n",
       "         1.67824879e-01,   1.67278647e-02,   3.53371091e-02,\n",
       "         4.82117794e-02,  -2.47564558e-02,   9.89421159e-02,\n",
       "        -3.30772549e-02,   1.11670204e-01,  -3.23002674e-02,\n",
       "        -4.79411520e-02,  -7.66797662e-02,   7.99388215e-02,\n",
       "         1.09337151e-01,  -3.02278693e-03,  -4.01138216e-02,\n",
       "         7.00161466e-03,  -6.85393810e-04,   2.57141832e-02,\n",
       "         2.81780623e-02,  -8.51317048e-02,   7.87730739e-02,\n",
       "        -1.96847077e-02,  -2.42261123e-02,  -1.10170797e-01,\n",
       "         4.67994846e-02,  -1.28926691e-02,  -1.35114295e-02,\n",
       "         1.73319578e-02,   8.36089104e-02,   3.53154242e-02,\n",
       "        -4.33812961e-02,  -3.88842300e-02,  -3.62613890e-03,\n",
       "        -2.55640466e-02,   2.74206400e-02,   1.55830299e-02,\n",
       "         1.63479727e-02,   3.44588509e-04,   5.23601361e-02,\n",
       "         2.10736338e-02,   1.36085227e-02,  -6.98029846e-02,\n",
       "         3.26058678e-02,  -1.32324442e-01,   5.40685467e-02,\n",
       "        -6.64548501e-02,   5.59341498e-02,  -8.43945593e-02,\n",
       "        -2.95452587e-02,   3.14888991e-02,  -6.81578531e-04,\n",
       "         4.47777985e-03,  -1.96789578e-02,  -4.30646315e-02,\n",
       "        -6.58707768e-02,  -1.28392139e-02,   4.66614030e-02,\n",
       "         8.93331394e-02,   2.04860289e-02,   3.27143213e-03,\n",
       "        -2.85526309e-02,   3.69441472e-02,   1.01295508e-01,\n",
       "         4.27961424e-02,   1.46195933e-01,   4.79748957e-02,\n",
       "         7.05682039e-02,  -6.94954172e-02,  -1.98068526e-02,\n",
       "         7.67135769e-02,  -4.99283969e-02,  -7.49715045e-03,\n",
       "        -2.54760478e-02,   1.94973461e-02,  -1.23438314e-02,\n",
       "        -1.21056633e-02,  -1.68620963e-02,  -2.79563107e-02,\n",
       "         6.22076765e-02,  -4.63964269e-02,   1.79981552e-02,\n",
       "        -7.81946257e-02,   2.63142735e-02,   3.18071619e-02,\n",
       "        -7.96308517e-02,   9.60515663e-02,  -1.66716264e-03,\n",
       "         2.87952907e-02,  -2.03982331e-02,  -3.94451693e-02,\n",
       "        -6.36960939e-02,  -3.68076889e-03,   1.04096152e-01,\n",
       "        -1.19179031e-02,  -3.96543592e-02,  -1.14724457e-01,\n",
       "         7.92745501e-03], dtype=float32)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's explore the doc2vec embeddings for a couple of questions\n",
    "d2v_model.docvecs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03838504, -0.08354634, -0.01117271,  0.02555202,  0.02572893,\n",
       "       -0.00395008,  0.14373481, -0.01543113,  0.0764803 , -0.15870024,\n",
       "       -0.05951281,  0.08448596,  0.10529042,  0.01061112,  0.06913876,\n",
       "       -0.02805477,  0.05633304, -0.01129845,  0.15861143,  0.04865975,\n",
       "       -0.01283512,  0.04331857, -0.01702989, -0.0086982 ,  0.01734035,\n",
       "       -0.02963531, -0.12042479, -0.02888017, -0.04327978, -0.05721083,\n",
       "        0.03572964, -0.06752493,  0.07382468,  0.09564143, -0.03470206,\n",
       "        0.09842788,  0.07821593, -0.00608268, -0.00607084,  0.07767332,\n",
       "        0.05771419,  0.11027338, -0.00085343, -0.0336242 ,  0.03213579,\n",
       "       -0.1111417 , -0.04521338, -0.01993181, -0.0444855 ,  0.01215197,\n",
       "        0.04180873,  0.07373083,  0.06221008, -0.0743958 , -0.05985229,\n",
       "        0.04578007,  0.10811017,  0.05333172, -0.09555285,  0.00241355,\n",
       "        0.06538348, -0.01062816, -0.09017845,  0.08363026, -0.15465143,\n",
       "       -0.08480647, -0.11142755,  0.0165417 , -0.08644711, -0.04465969,\n",
       "        0.09864585, -0.05533931,  0.12738566, -0.01260554, -0.0362331 ,\n",
       "        0.07940394, -0.07507113,  0.06329417, -0.03922332,  0.06549557,\n",
       "        0.0094242 , -0.01605289, -0.01440844,  0.11157755,  0.07229158,\n",
       "        0.02192817,  0.04522106,  0.03506562,  0.02186571,  0.03243335,\n",
       "        0.07693046, -0.03338346,  0.13970137, -0.05587772, -0.04371933,\n",
       "        0.00649647, -0.10948778,  0.00591358,  0.00543918,  0.00236835,\n",
       "        0.00351328, -0.07470205,  0.08915816, -0.02498518,  0.00424507,\n",
       "       -0.03686439,  0.02308258, -0.03321677, -0.04273435, -0.0850113 ,\n",
       "        0.00123791,  0.11449374, -0.00192936,  0.01508509,  0.13029523,\n",
       "        0.05860434, -0.02397916,  0.10012724,  0.07892329, -0.01368402,\n",
       "       -0.09932049,  0.00052402,  0.00359981, -0.08164617, -0.0014348 ,\n",
       "       -0.08732763,  0.08597995, -0.02788777,  0.01573581, -0.029498  ,\n",
       "       -0.00314387, -0.2022751 ,  0.00087353,  0.05194801, -0.0057257 ,\n",
       "        0.07773967,  0.01681331,  0.03334557,  0.06881361,  0.02219499,\n",
       "       -0.00219217,  0.04917095, -0.0463048 , -0.02291984,  0.02506277,\n",
       "        0.03898752,  0.08850694, -0.06808773, -0.05654785,  0.00454626,\n",
       "        0.00042608, -0.04839093,  0.02338489,  0.01879683,  0.14469604,\n",
       "        0.02216726, -0.10446818,  0.06555036, -0.04997394,  0.01812216,\n",
       "        0.07633685, -0.17787543,  0.07129361, -0.06199703, -0.02674748,\n",
       "       -0.00178925, -0.05563731, -0.0192291 ,  0.03297101,  0.01898262,\n",
       "        0.12411243, -0.0893457 , -0.03003363,  0.00030705,  0.15198196,\n",
       "        0.02192127,  0.00331561,  0.04315428, -0.04840595,  0.06733417,\n",
       "        0.00920503,  0.18864946, -0.07018646,  0.00781856,  0.00299604,\n",
       "       -0.12074558,  0.07752456, -0.03176114,  0.04480715,  0.05237485,\n",
       "        0.00801149, -0.0562769 ,  0.0476217 ,  0.1496266 ,  0.08285981,\n",
       "        0.00610499, -0.02610745, -0.01407566, -0.01019943, -0.06192192,\n",
       "        0.12121455, -0.02862725,  0.01003367,  0.0783466 , -0.12206826,\n",
       "       -0.05363217, -0.00791549, -0.06000144,  0.08126167,  0.10694624,\n",
       "       -0.06636587,  0.02359649,  0.07875881,  0.05088725, -0.051137  ,\n",
       "        0.02801621,  0.1311343 , -0.09814876, -0.0186863 , -0.05337596,\n",
       "       -0.06544758, -0.00047606, -0.04430619,  0.07403737,  0.06803849,\n",
       "        0.00084512,  0.1185103 , -0.03516137,  0.07316735, -0.07791293,\n",
       "        0.0238212 ,  0.07914039,  0.01545581, -0.00707767,  0.05917696,\n",
       "        0.0817143 ,  0.01553852, -0.10567094,  0.03112151, -0.01801712,\n",
       "        0.00710409,  0.02259243,  0.11180086,  0.12910199,  0.07076239,\n",
       "       -0.03959491,  0.00467908, -0.02393432,  0.01249379,  0.01922726,\n",
       "       -0.01295454, -0.07693386,  0.0767322 , -0.0083531 , -0.0370652 ,\n",
       "        0.11867902, -0.03109996, -0.08929398,  0.00958289, -0.01620219,\n",
       "        0.00528248,  0.04054828, -0.04444207, -0.0120957 , -0.04593328,\n",
       "        0.00428468,  0.06478503,  0.00146359, -0.00731602, -0.02511928,\n",
       "        0.05682765,  0.09684055,  0.02820769, -0.07562684, -0.03636879,\n",
       "        0.1451875 , -0.05839446,  0.08541848,  0.02703751, -0.01609878,\n",
       "        0.13181694, -0.07182544, -0.06639718, -0.06416993, -0.103677  ,\n",
       "        0.01662275,  0.01100136,  0.08172586, -0.06893674,  0.04385788,\n",
       "       -0.04760811, -0.05831423,  0.03314201,  0.0028576 , -0.06815395,\n",
       "        0.04460598,  0.05311768,  0.11609212,  0.02264934,  0.11004926,\n",
       "        0.11245972,  0.06430943, -0.04171504, -0.00831974, -0.01357121,\n",
       "        0.00608291, -0.12838568, -0.01857146,  0.1393564 , -0.06417458,\n",
       "        0.20038687,  0.04894053, -0.03142735,  0.03627521, -0.04405948,\n",
       "       -0.01411855,  0.06159036, -0.01038319,  0.10747083, -0.00893531,\n",
       "       -0.03401076, -0.01041919, -0.01380159, -0.04864608,  0.05170446,\n",
       "        0.00748538, -0.04167327, -0.02246466,  0.02345046, -0.00036713,\n",
       "        0.01875481,  0.06352995,  0.09803861,  0.02077123,  0.04642938,\n",
       "        0.02202806,  0.00497363,  0.03147885,  0.07426134, -0.01754153,\n",
       "       -0.06102468, -0.03327289,  0.08371341,  0.01667102, -0.03115667,\n",
       "        0.06921744,  0.00165767, -0.09631814, -0.01162771,  0.01436776,\n",
       "       -0.07111451, -0.06615865, -0.00815812,  0.04578002, -0.11199663,\n",
       "       -0.03628123, -0.05785848, -0.14610918,  0.05681086,  0.0236351 ,\n",
       "        0.03612708,  0.10963249, -0.02342856,  0.01663068,  0.0019997 ,\n",
       "       -0.00029696, -0.00149165,  0.02451309,  0.02369537,  0.02422578,\n",
       "        0.01134406,  0.05594631,  0.02628393,  0.01650553, -0.01986309,\n",
       "       -0.05635323, -0.0110849 , -0.00235941, -0.12283967, -0.04126374,\n",
       "        0.04925755, -0.05947639, -0.02603597,  0.06201125,  0.04238029,\n",
       "       -0.04166847, -0.01049233, -0.04016567,  0.09293377,  0.04529359,\n",
       "        0.03760782, -0.02423551, -0.0374146 , -0.15182815, -0.08009826,\n",
       "       -0.03445737, -0.03831704, -0.15529798, -0.02069845, -0.00039807], dtype=float32)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2v_model.docvecs[808579]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d2v_model.docvecs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "808580"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d2v_model.docvecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "404290"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2v_model.corpus_count/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'h1b_visa', 0.6292389035224915),\n",
       " (u'green_card', 0.5542278289794922),\n",
       " (u'visa', 0.5406888723373413),\n",
       " (u'f1_visa', 0.5315204858779907),\n",
       " (u'i-140', 0.5080620050430298),\n",
       " (u'ead', 0.5021740794181824),\n",
       " (u'h1-b_visa', 0.49482202529907227),\n",
       " (u'h-1b_visa', 0.487729012966156),\n",
       " (u'h1-b', 0.4810710549354553),\n",
       " (u'b1/b2_visa', 0.47847169637680054)]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2v_model.most_similar('h1b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_vectors_broad (filename, offset, num_rec):\n",
    "    \"\"\"\n",
    "    saves the sentence vectors of all question pairs \n",
    "    in a csv file        \n",
    "    \"\"\"\n",
    "    with open(filename, 'w') as fout:\n",
    "        for i in tqdm(xrange(num_rec)):\n",
    "            for word in d2v_model.docvecs[i]:\n",
    "                fout.write(str(word)+',')\n",
    "            for word in d2v_model.docvecs[i+offset]:\n",
    "                fout.write(str(word)+',')\n",
    "            fout.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d2v_data400_filepath = r'd2v_data400_all.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404290 404290\n"
     ]
    }
   ],
   "source": [
    "offset = d2v_model.corpus_count/2\n",
    "nrec = d2v_model.corpus_count/2\n",
    "print offset, nrec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if 1==1:\n",
    "    save_vectors_broad(d2v_data400_filepath, offset, nrec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
